{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.multi_modal_llms.azure_openai import AzureOpenAIMultiModal\n",
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import ( \n",
    "    SimpleDirectoryReader, \n",
    "    StorageContext, \n",
    "    Settings, \n",
    "    PromptTemplate\n",
    ")\n",
    "from llama_index.core.ingestion import DocstoreStrategy\n",
    "# from llama_index.embeddings.vertex import VertexTextEmbedding\n",
    "from llama_index.core.schema import ImageNode\n",
    "from llama_index.core.query_engine import SimpleMultiModalQueryEngine\n",
    "# from langchain.chat_models import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "OPENAI_API_KEY = \"3a6b230b917b4893a150f0ad7fa126cf\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://cpe-clx-openai.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\" #\"2024-02-15-preview\"\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# Replace the path with the path to the service account key file\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\CQTF47\\\\Downloads\\\\Dipjyoti RAG POC\\\\devtest-sa.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed_model = VertexTextEmbedding(project=\"msi-genai-frontdoor-499476\", location=\"us-east1\", credentials = os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "embed_model_openai = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    # deployment_name=\"cpe-clx-embedding\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"] ,\n",
    "    azure_deployment=\"cpe-clx-embedding\"\n",
    ")\n",
    "\n",
    "# azure_llm = AzureChatOpenAI(\n",
    "#     model=\"cpe-clx-gpt4o\",\n",
    "#     azure_deployment=\"cpe-clx-gpt4o\",\n",
    "#     api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "#     azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "#     api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "# )\n",
    "\n",
    "openai_mm_llm = AzureOpenAIMultiModal(\n",
    "    engine=\"cpe-clx-gpt4o\",\n",
    "    api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
    "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "    model=\"gpt-4o-2024-05-13\",\n",
    "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    max_new_tokens=1500,\n",
    "    max_retries = 1\n",
    ")\n",
    "\n",
    "Settings.llm = openai_mm_llm\n",
    "Settings.embed_model = embed_model_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_name = r\"C:\\Users\\CQTF47\\Desktop\\IU Masters\\Thesis\\pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(path=\"financial_risk_analysis_vector_db/\")\n",
    "\n",
    "text_store = QdrantVectorStore(\n",
    "    client=client, collection_name=f\"pdf_text_collection\"\n",
    ")\n",
    "# image_store = QdrantVectorStore(\n",
    "#     client=client, collection_name=f\"pdf_image_collection\"\n",
    "# )\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=text_store\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_names = os.listdir(directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = []\n",
    "\n",
    "def find_and_remove_duplicates_from_vectordb(client, collection_name, document_name):\n",
    "    data = client.scroll(\n",
    "            collection_name=collection_name,\n",
    "            scroll_filter=models.Filter(\n",
    "                must=[\n",
    "                    models.FieldCondition(\n",
    "                        key=\"file_name\", match=models.MatchValue(value=document_name)\n",
    "                    ),\n",
    "                ],\n",
    "            ),\n",
    "        )\n",
    "    \n",
    "    if len(data[0]) > 0:\n",
    "        print(f\"Document {doc} already exists in the collection {collection_name}\")\n",
    "        print(\"Do you want to overwrite it? (y/n)\")\n",
    "        choice = input()\n",
    "        if choice.lower() != 'y':\n",
    "            exclude.append(f\"*{doc}*\")\n",
    "        else:\n",
    "            print(f\"Removing duplicates for {doc} from the collection {collection_name}\")\n",
    "            client.delete(collection_name=collection_name, points_selector=models.Filter(\n",
    "                must=[\n",
    "                    models.FieldCondition(\n",
    "                        key=\"file_name\", match=models.MatchValue(value=document_name)\n",
    "                    ),\n",
    "                ],\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if text_store._collection_exists(f\"{directory_name}_text_collection\"):\n",
    "    for doc in document_names:\n",
    "        find_and_remove_duplicates_from_vectordb(client, f\"{directory_name}_text_collection\", doc)\n",
    "        # find_and_remove_duplicates_from_vectordb(client, f\"{directory_name}_image_collection\", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(f\"{directory_name}/\", filename_as_id=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bfb1ea60f6142d08f0acd5d2e0d5cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e2cc310a3f4779bb702ad71393cc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/82 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = MultiModalVectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    storage_context=storage_context,\n",
    "    show_progress = True,\n",
    "    timeout = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tmpl_str = (\n",
    "    \"Context information is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the context information and not prior knowledge, \"\n",
    "    \"answer the query.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_tmpl = PromptTemplate(qa_tmpl_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(text_qa_template=qa_tmpl, similarity_top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ''' \n",
    "            create the slides content for thesis presentation of 30 minutes on the topic.\n",
    "'''\n",
    "response = query_engine.query(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Below is a suggested outline and content for a 30-minute thesis presentation on the topic \"AI Stock Analyst: Financial Chatbot Using Large Language Models\" by Gummadi Sai Dheeraj.\n",
      "\n",
      "### Slide 1: Title Slide\n",
      "- **Title:** AI Stock Analyst: Financial Chatbot Using Large Language Models\n",
      "- **Presenter:** Gummadi Sai Dheeraj\n",
      "- **Matriculation Number:** 3210935\n",
      "- **Advisor:** Professor Broweleit, Tobias\n",
      "- **University:** University of Applied Science - Online\n",
      "- **Program:** Masters in Data Science (MSDS60ECTS)\n",
      "- **Delivery Date:** January 08, 2025\n",
      "\n",
      "### Slide 2: Introduction\n",
      "- **Overview of the Presentation:**\n",
      "  - Introduction to the topic\n",
      "  - Problem Statement\n",
      "  - Objectives\n",
      "  - Methodology\n",
      "  - Results\n",
      "  - Conclusion and Future Work\n",
      "\n",
      "### Slide 3: Background\n",
      "- **Introduction to Financial Chatbots:**\n",
      "  - Definition and importance\n",
      "  - Current state of financial chatbots\n",
      "- **Large Language Models (LLMs):**\n",
      "  - Definition and examples (e.g., GPT-3, GPT-4)\n",
      "  - Relevance to financial chatbots\n",
      "\n",
      "### Slide 4: Problem Statement\n",
      "- **Challenges in Financial Analysis:**\n",
      "  - Complexity of financial data\n",
      "  - Need for real-time analysis\n",
      "  - Accuracy and reliability issues\n",
      "- **Limitations of Existing Solutions:**\n",
      "  - Traditional financial analysis tools\n",
      "  - Existing chatbots and their limitations\n",
      "\n",
      "### Slide 5: Objectives\n",
      "- **Primary Objective:**\n",
      "  - Develop an AI-powered financial chatbot using LLMs\n",
      "- **Secondary Objectives:**\n",
      "  - Enhance accuracy and reliability of financial predictions\n",
      "  - Improve user interaction and experience\n",
      "  - Address the issue of hallucinations in LLMs\n",
      "\n",
      "### Slide 6: Literature Review\n",
      "- **Overview of Existing Research:**\n",
      "  - Financial fraud detection (reference to \"Detailed_Report_on_financial_fraud_detection.pdf\")\n",
      "  - Overcoming hallucinations in LLMs (reference to \"Overcoming Hallucinations with the Trustworthy Language Model.pdf\")\n",
      "- **Key Findings:**\n",
      "  - Importance of trustworthy language models\n",
      "  - Techniques to mitigate hallucinations\n",
      "\n",
      "### Slide 7: Methodology\n",
      "- **Data Collection:**\n",
      "  - Sources of financial data\n",
      "  - Data preprocessing techniques\n",
      "- **Model Selection:**\n",
      "  - Choice of LLM (e.g., GPT-4)\n",
      "  - Justification for the choice\n",
      "- **Model Training:**\n",
      "  - Training process\n",
      "  - Hyperparameter tuning\n",
      "\n",
      "### Slide 8: System Architecture\n",
      "- **Overview of the System:**\n",
      "  - Components of the financial chatbot\n",
      "  - Interaction flow between components\n",
      "- **Technical Details:**\n",
      "  - Backend infrastructure\n",
      "  - Integration with financial data sources\n",
      "\n",
      "### Slide 9: Implementation\n",
      "- **Development Process:**\n",
      "  - Tools and technologies used\n",
      "  - Implementation steps\n",
      "- **Challenges Faced:**\n",
      "  - Data quality issues\n",
      "  - Computational limitations\n",
      "\n",
      "### Slide 10: Results\n",
      "- **Performance Metrics:**\n",
      "  - Accuracy of financial predictions\n",
      "  - User satisfaction scores\n",
      "- **Comparison with Existing Solutions:**\n",
      "  - Benchmarking against traditional tools\n",
      "  - Improvements observed\n",
      "\n",
      "### Slide 11: Case Study\n",
      "- **Real-world Application:**\n",
      "  - Example scenario of the chatbot in action\n",
      "  - User interaction and chatbot responses\n",
      "- **Impact Analysis:**\n",
      "  - Benefits to users\n",
      "  - Potential limitations\n",
      "\n",
      "### Slide 12: Conclusion\n",
      "- **Summary of Findings:**\n",
      "  - Key achievements of the project\n",
      "  - Contributions to the field of financial analysis\n",
      "- **Future Work:**\n",
      "  - Potential improvements\n",
      "  - Areas for further research\n",
      "\n",
      "### Slide 13: Q&A\n",
      "- **Invitation for Questions:**\n",
      "  - Open the floor for questions and discussions\n",
      "\n",
      "### Slide 14: Acknowledgements\n",
      "- **Acknowledgements:**\n",
      "  - Advisor: Professor Broweleit, Tobias\n",
      "  - University of Applied Science - Online\n",
      "  - Family and friends for their support\n",
      "\n",
      "### Slide 15: References\n",
      "- **Citations:**\n",
      "  - List of references used in the thesis\n",
      "\n",
      "### Slide 16: Contact Information\n",
      "- **Contact Details:**\n",
      "  - Email: gummadi.saidheeraj@iu-study.org\n",
      "  - LinkedIn profile (if applicable)\n",
      "\n",
      "This outline provides a structured approach to presenting your thesis, ensuring that all key aspects are covered within the 30-minute timeframe. Adjust the content and slides as needed to fit your specific research and findings.\n"
     ]
    }
   ],
   "source": [
    "print(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a 30-minute thesis presentation on \"AI Stock Analyst: Financial Chatbot Using Large Language Models\" can be effectively divided into five sections. Here is a suggested structure and content for each section:\n",
      "\n",
      "### Section 1: Introduction (5 minutes)\n",
      "- **Title Slide**\n",
      "  - Title: AI Stock Analyst: Financial Chatbot Using Large Language Models\n",
      "  - Your Name: Gummadi Sai Dheeraj\n",
      "  - Advisor: Professor Broweleit, Tobias\n",
      "  - University: University of Applied Science - Online\n",
      "  - Date: January 08, 2025\n",
      "\n",
      "- **Overview**\n",
      "  - Brief introduction to the topic\n",
      "  - Importance of AI in financial markets\n",
      "  - Objectives of the thesis\n",
      "\n",
      "- **Agenda**\n",
      "  - Outline the five sections of the presentation\n",
      "\n",
      "### Section 2: Background and Literature Review (5 minutes)\n",
      "- **The Evolving Landscape of Financial Markets**\n",
      "  - Changes and challenges in financial stock analysis\n",
      "  - The need for advanced analytical tools\n",
      "\n",
      "- **Literature Review**\n",
      "  - Overview of existing research on machine learning in finance\n",
      "  - Key studies on LLMs in financial analysis\n",
      "  - Gaps in current research that this thesis aims to address\n",
      "\n",
      "### Section 3: Methodology (10 minutes)\n",
      "- **Framework Overview**\n",
      "  - Description of the overall framework used in the study\n",
      "  - Dataset configuration and preparation\n",
      "\n",
      "- **Instruction-Based Fine-Tuning and QLoRA Compression**\n",
      "  - Explanation of fine-tuning techniques\n",
      "  - Details on QLoRA compression\n",
      "\n",
      "- **Evaluation Techniques**\n",
      "  - Specific prompts and outputs used for evaluation\n",
      "  - Criteria for assessing model performance\n",
      "\n",
      "- **Comparison of Models**\n",
      "  - GPT-4o vs Gemini 1.5 Flash\n",
      "  - Key differences and similarities\n",
      "\n",
      "### Section 4: Experimental Results and Analysis (5 minutes)\n",
      "- **Model Robustness and Performance**\n",
      "  - Handling a wide range of text lengths\n",
      "  - Effects of different features on model performance\n",
      "\n",
      "- **Experimental Results**\n",
      "  - Validation of the model's effectiveness\n",
      "  - Actionable insights for investors\n",
      "\n",
      "- **Case Studies**\n",
      "  - Examples of the chatbot's recommendations\n",
      "  - Analysis of post-earnings stock fluctuations\n",
      "\n",
      "### Section 5: Conclusion and Future Work (5 minutes)\n",
      "- **Summary of Findings**\n",
      "  - Recap of key results and their implications\n",
      "  - The chatbot's ability to democratize financial insights\n",
      "\n",
      "- **Future Work**\n",
      "  - Integration with personal data for broader applications\n",
      "  - Potential use cases: personalized investment advice, risk assessment, fraud detection, customer service, investment research, portfolio management\n",
      "\n",
      "- **Q&A**\n",
      "  - Open the floor for questions from the audience\n",
      "\n",
      "### Additional Tips:\n",
      "- **Visual Aids**\n",
      "  - Use graphs, charts, and diagrams to illustrate key points\n",
      "  - Include screenshots or demos of the chatbot in action\n",
      "\n",
      "- **Practice Timing**\n",
      "  - Ensure each section fits within the allocated time\n",
      "  - Practice delivering the presentation to maintain a steady pace\n",
      "\n",
      "- **Engage the Audience**\n",
      "  - Ask rhetorical questions to keep the audience engaged\n",
      "  - Use clear and concise language to explain complex concepts\n",
      "\n",
      "This structure should help you deliver a comprehensive and engaging presentation on your thesis topic.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            create the slides content for thesis presentation of 30 minutes on the topic: \"AI Stock Analyst: Financial Chatbot Using Large Language Models\". Divide the content into 5 sections.\n",
    "'''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a 30-minute thesis presentation on \"AI Stock Analyst: Financial Chatbot Using Large Language Models\" can be effectively divided into six sections. Here is a suggested outline for the slides content:\n",
      "\n",
      "### Section 1: Introduction (5 minutes)\n",
      "- **Slide 1: Title Slide**\n",
      "  - Title: AI Stock Analyst: Financial Chatbot Using Large Language Models\n",
      "  - Your Name: Gummadi Sai Dheeraj\n",
      "  - University: University of Applied Science - Online\n",
      "  - Advisor: Professor Broweleit, Tobias\n",
      "  - Date: January 08, 2025\n",
      "\n",
      "- **Slide 2: Overview**\n",
      "  - Brief introduction to the topic\n",
      "  - Importance of AI in financial markets\n",
      "  - Objectives of the thesis\n",
      "\n",
      "### Section 2: Background and Literature Review (5 minutes)\n",
      "- **Slide 3: The Evolving Landscape of Financial Markets**\n",
      "  - Historical context\n",
      "  - Current trends and challenges\n",
      "\n",
      "- **Slide 4: Literature Review**\n",
      "  - Key studies and their findings\n",
      "  - Gaps in existing research\n",
      "  - Relevance to your work\n",
      "\n",
      "### Section 3: Methodology (5 minutes)\n",
      "- **Slide 5: Research Framework**\n",
      "  - Overview of the methodology\n",
      "  - Dataset configuration\n",
      "  - Instruction-based fine-tuning\n",
      "\n",
      "- **Slide 6: Technical Components**\n",
      "  - QLoRA compression\n",
      "  - Evaluation using specific prompts and outputs\n",
      "\n",
      "### Section 4: Implementation and Model Details (5 minutes)\n",
      "- **Slide 7: Model Architecture**\n",
      "  - Description of the chatbot system\n",
      "  - Use of RAG framework\n",
      "\n",
      "- **Slide 8: Data Sources and Processing**\n",
      "  - Data retrieval from Yahoo Finance\n",
      "  - Sentiment analysis from news articles\n",
      "\n",
      "### Section 5: Results and Discussion (5 minutes)\n",
      "- **Slide 9: Experimental Results**\n",
      "  - Performance metrics\n",
      "  - Comparison between Base and Full datasets\n",
      "\n",
      "- **Slide 10: Analysis of Findings**\n",
      "  - Insights from the results\n",
      "  - Implications for investors\n",
      "\n",
      "### Section 6: Conclusion and Future Work (5 minutes)\n",
      "- **Slide 11: Conclusion**\n",
      "  - Summary of key findings\n",
      "  - Validation of the model's effectiveness\n",
      "\n",
      "- **Slide 12: Future Work**\n",
      "  - Potential enhancements\n",
      "  - Broader applications (e.g., personalized investment advice, risk assessment, fraud detection)\n",
      "\n",
      "- **Slide 13: Q&A**\n",
      "  - Open the floor for questions\n",
      "\n",
      "### Additional Tips:\n",
      "- **Timing:** Ensure each section is concise to fit within the 5-minute timeframe.\n",
      "- **Visuals:** Use graphs, charts, and diagrams to illustrate key points.\n",
      "- **Practice:** Rehearse the presentation to maintain a steady pace and ensure clarity.\n",
      "\n",
      "This structure will help you deliver a comprehensive and engaging presentation within the allotted time.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            create the slides content for thesis presentation of 30 minutes on the topic: \"AI Stock Analyst: Financial Chatbot Using Large Language Models\". Divide the content into 6 sections.\n",
    "'''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladies and Gentlemen,\n",
      "\n",
      "Good [morning/afternoon/evening]. Thank you for joining me today. I am excited to present an overview of my thesis titled \"AI Stock Analyst: Financial Chatbot Using Large Language Models.\" This research delves into the transformative role of Artificial Intelligence (AI) in financial markets and aims to bridge the gap in financial stock analysis through innovative methodologies.\n",
      "\n",
      "**Brief Introduction to the Topic**\n",
      "\n",
      "The financial markets have experienced significant transformations over the past few decades. These changes have been driven by technological advancements, globalization, and the increasing complexity of financial instruments. As we navigate through the digital age, the sheer volume of information available to stock market participants has grown exponentially. Financial news, market data, economic indicators, social media sentiment, and corporate disclosures flood the information channels daily. This phenomenon, known as information overload, presents both opportunities and challenges for investors, analysts, and financial institutions.\n",
      "\n",
      "**Importance of AI in Financial Markets**\n",
      "\n",
      "In this evolving landscape, AI has emerged as a powerful tool to address the complexities and challenges of modern financial markets. AI, particularly through the use of Large Language Models (LLMs), has the potential to revolutionize financial analysis and decision-making processes. Here are a few key reasons why AI is crucial in financial markets:\n",
      "\n",
      "1. **Handling Information Overload**: AI excels at processing vast amounts of data quickly and accurately. This capability is particularly valuable in financial markets, where timely and accurate information is crucial. By filtering out the noise and identifying valuable insights, AI can help investors make more informed decisions.\n",
      "\n",
      "2. **Reducing Cognitive Biases**: The abundance of information can exacerbate cognitive biases, such as confirmation bias, where individuals favor information that confirms their preexisting beliefs. AI can provide more objective, data-driven insights, reducing the impact of these biases on decision-making.\n",
      "\n",
      "3. **Enhancing Market Efficiency**: Traditional methods of financial analysis, such as fundamental and technical analysis, face significant limitations in the context of modern financial markets. AI can enhance these methods by providing more accurate predictions and identifying patterns that may not be apparent through conventional analysis.\n",
      "\n",
      "4. **Democratizing Financial Analysis**: AI and LLMs can make sophisticated financial analysis tools accessible to a broader audience. This democratization can empower individual investors and smaller financial institutions, leveling the playing field in the financial markets.\n",
      "\n",
      "**Objectives of the Thesis**\n",
      "\n",
      "The primary objective of this thesis is to explore the application of AI, specifically Large Language Models, in financial stock analysis. The research aims to address several key challenges and opportunities in this domain:\n",
      "\n",
      "1. **Bridging the Gap in Financial Stock Analysis**: Traditional models often fall short in providing clear, understandable explanations for their predictions. This thesis aims to develop AI-driven models that offer transparent and interpretable insights, helping investors understand the rationale behind the recommendations.\n",
      "\n",
      "2. **Combining AI with Conventional Methods**: The research will explore how AI can be integrated with traditional financial analysis methods, such as fundamental and technical analysis. By combining the strengths of both approaches, the thesis aims to develop more robust and accurate stock analysis models.\n",
      "\n",
      "3. **Developing a Financial Chatbot**: One of the key innovations of this thesis is the development of a financial chatbot using LLMs. This chatbot will provide real-time, data-driven insights and recommendations to investors, helping them navigate the complexities of the financial markets.\n",
      "\n",
      "4. **Evaluating the Effectiveness of AI Models**: The thesis will rigorously evaluate the performance of AI models in various financial analysis tasks, such as sentiment analysis, risk assessment, portfolio optimization, and stock price prediction. The goal is to identify the strengths and limitations of these models and suggest areas for further research and improvement.\n",
      "\n",
      "In conclusion, this thesis aims to contribute to the growing body of research on AI in financial markets by developing innovative models and tools that enhance financial analysis and decision-making processes. I look forward to sharing more details about my research and its findings in the subsequent sections of this presentation.\n",
      "\n",
      "Thank you for your attention.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 10 minute speech for slide 2 Overview that covers the following points:\n",
    "                - Brief introduction to the topic\n",
    "                - Importance of AI in financial markets\n",
    "                - Objectives of the thesis\n",
    "\n",
    "'''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Evolving Landscape of Financial Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ladies and Gentlemen,\n",
      "\n",
      "Good [morning/afternoon/evening]. Today, I am honored to speak to you about \"The Evolving Landscape of Financial Markets,\" a topic that is both fascinating and crucial for understanding the dynamics of our global economy. In the next few minutes, I will cover the historical context of financial markets, current trends, and the challenges we face today.\n",
      "\n",
      "**Historical Context**\n",
      "\n",
      "To appreciate the current state of financial markets, it's essential to look back at their evolution. Over the past few decades, financial markets have undergone significant transformations. Historically, markets were relatively simple and localized. Transactions were conducted in person, and information flow was slow and limited. The primary methods of analysis were fundamental and technical, relying heavily on manual calculations and human intuition.\n",
      "\n",
      "However, the landscape began to change dramatically with the advent of technological advancements. The introduction of computers and the internet revolutionized the way financial data was processed and shared. Globalization further accelerated this transformation, breaking down geographical barriers and enabling the seamless flow of capital across borders. The increasing complexity of financial instruments, such as derivatives and structured products, added new dimensions to market operations.\n",
      "\n",
      "**Current Trends and Challenges**\n",
      "\n",
      "Fast forward to today, and we find ourselves in an era characterized by rapid technological innovation and an overwhelming volume of information. The digital age has brought about what we call \"information overload.\" Every day, financial news, market data, economic indicators, social media sentiment, and corporate disclosures flood the information channels. This phenomenon presents both opportunities and challenges for investors, analysts, and financial institutions.\n",
      "\n",
      "One of the significant challenges is decision paralysis. The sheer volume of data can overwhelm investors, making it difficult to identify the right information, leading to indecision or delayed action. Additionally, distinguishing between valuable insights (signal) and irrelevant data (noise) has become increasingly difficult, potentially leading to poor investment decisions.\n",
      "\n",
      "Cognitive biases are also exacerbated by the abundance of information. For instance, confirmation bias can lead individuals to favor information that confirms their preexisting beliefs, skewing their judgment and decision-making processes.\n",
      "\n",
      "The rise of information overload has profound implications for financial markets. Rapid dissemination of news and data can lead to increased market volatility as investors react to new information, often without fully understanding its implications. This environment promotes short-term trading strategies, as investors look to take advantage of quick market fluctuations instead of focusing on long-term fundamentals. Consequently, this can create inefficiencies in the market, as not all participants have equal access to or the ability to process information effectively.\n",
      "\n",
      "Traditional methods of financial analysis and decision-making, such as fundamental analysis, technical analysis, and quantitative models, face significant limitations in this modern context. While these methods have their merits, they often struggle to keep pace with the dynamic and complex nature of today's financial markets.\n",
      "\n",
      "In conclusion, the evolving landscape of financial markets presents a unique set of challenges and opportunities. As we navigate this complex environment, it is crucial to leverage advanced technologies, such as Artificial Intelligence and Large Language Models, to enhance our analytical capabilities and make more informed decisions. By doing so, we can better manage the risks and capitalize on the opportunities that this new era of financial markets has to offer.\n",
      "\n",
      "Thank you for your attention.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech for slide \"The Evolving Landscape of Financial Markets\" that covers the following points:\n",
    "                - Historical context\n",
    "                - Current trends and challenges\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Speech:**\n",
      "\n",
      "Good [morning/afternoon/evening] everyone,\n",
      "\n",
      "Today, I am excited to present the literature review section of my thesis, which focuses on the intersection of financial data analysis and natural language processing (NLP). This review highlights key studies, identifies gaps in existing research, and discusses the relevance of these findings to my work.\n",
      "\n",
      "**Key Studies and Their Findings:**\n",
      "\n",
      "The importance of analyst reports in identifying stock and market trends has been well-documented by researchers such as Jegadeesh et al. Their work has inspired subsequent research that delves into the financial metrics and analysts' opinions within these reports. Studies by authors like Liu and Steins, Savavidya and Saha, and Prabhu et al. have explored the potential benefits of chatbots for customer service in various industries, demonstrating improvements in multi-turn answer accuracy, online banking, and rapid customer care.\n",
      "\n",
      "In the realm of NLP, the advent of Large Language Models (LLMs) has revolutionized the field. GPT-3, with its 175 billion parameters, has shown remarkable performance in tasks such as code generation, reading comprehension, and question answering. This has paved the way for even larger models, with sizes growing to 280 billion, 540 billion, and even 1 trillion parameters. Research has also extended to different training objectives, multilingual models, and more efficient and smaller models.\n",
      "\n",
      "**Gaps in Existing Research:**\n",
      "\n",
      "Despite these advancements, there are still significant gaps in the existing research. Much of the current literature focuses on the financial metrics or analysts' opinions within reports, often overlooking the potential insights hidden within the text. Additionally, there is a bias toward buy recommendations in these reports, which can skew the analysis.\n",
      "\n",
      "Moreover, while LLMs have shown great promise, there is a need for more research into their application in specific domains, such as financial fraud detection. The integration of NLP techniques with financial data analysis remains underexplored, particularly in the context of improving traditional literature review methods and enhancing customer service through chatbots.\n",
      "\n",
      "**Relevance to My Work:**\n",
      "\n",
      "My research aims to address these gaps by leveraging the power of LLMs to analyze financial data and improve the accuracy of financial fraud detection. By utilizing the Alpha Vantage API to collect comprehensive financial data, including company profiles, weekly stock price data, and income statements, I aim to develop a robust model that can identify fraudulent activities with greater precision.\n",
      "\n",
      "Furthermore, my work explores the potential of chatbots in providing efficient customer support, drawing on the findings of studies that have demonstrated their effectiveness in various industries. By integrating these technologies, I hope to contribute to the development of more reliable and insightful financial analysis tools.\n",
      "\n",
      "In conclusion, the literature review highlights the significant progress made in the fields of financial data analysis and NLP, while also identifying areas that require further exploration. My research seeks to bridge these gaps and contribute to the advancement of financial fraud detection and customer service technologies.\n",
      "\n",
      "Thank you for your attention.\n",
      "\n",
      "**Slide Content:**\n",
      "\n",
      "**Slide Title: Literature Review**\n",
      "\n",
      "**Key Studies and Their Findings:**\n",
      "- Analyst reports as reliable sources for stock and market trends (Jegadeesh et al.)\n",
      "- Benefits of chatbots in customer service (Liu and Steins, Savavidya and Saha, Prabhu et al.)\n",
      "- Advancements in Large Language Models (LLMs) like GPT-3 and beyond\n",
      "\n",
      "**Gaps in Existing Research:**\n",
      "- Overlooked insights within the text of analyst reports\n",
      "- Bias toward buy recommendations in financial reports\n",
      "- Need for domain-specific applications of LLMs in financial fraud detection\n",
      "- Underexplored integration of NLP with financial data analysis\n",
      "\n",
      "**Relevance to My Work:**\n",
      "- Leveraging LLMs for improved financial fraud detection\n",
      "- Utilizing comprehensive financial data from Alpha Vantage API\n",
      "- Enhancing customer service through chatbot integration\n",
      "- Bridging gaps in current research to develop reliable financial analysis tools\n",
      "\n",
      "Thank you!\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech and the slide content for slide \"Literature Review\" that covers the following points:\n",
    "                - Key studies and their findings\n",
    "                - Gaps in existing research\n",
    "                - Relevance to your work\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Speech:**\n",
      "\n",
      "Good [morning/afternoon/evening] everyone,\n",
      "\n",
      "Today, I am excited to present to you the research framework for our study on enhancing stock analysis using advanced Natural Language Processing (NLP) techniques, dynamic data retrieval systems, and Large Language Models (LLMs). Our goal is to provide comprehensive and reliable stock analysis by integrating both fundamental and technical evaluation with the trustworthiness of LLMs. Let's dive into the key components of our methodology.\n",
      "\n",
      "**Overview of the Methodology:**\n",
      "\n",
      "Our research methodology is designed to ensure accuracy and efficiency in stock market analysis. We have divided our approach into several key steps, each contributing to the overall system's effectiveness. These steps include data collection, data processing, and the integration of LLMs with Retrieval-Augmented Generation (RAG) pipelines. By leveraging these advanced techniques, we aim to revolutionize the analysis and interpretation of stock market data, enabling precise, data-driven investment decisions.\n",
      "\n",
      "**Data and Prompting:**\n",
      "\n",
      "The data collection process is a crucial part of our methodology. We start by identifying the companies for which stock analysis needs to be performed. We include all companies listed on Yahoo Finance, ensuring comprehensive coverage across various industries. This approach eliminates market capitalization constraints, allowing us to analyze companies of all sizes.\n",
      "\n",
      "Once the target companies are identified, we collect detailed stock information from Yahoo Finance. This includes key metrics such as Earnings Per Share (EPS) trends over 90, 60, and 30 days, as well as the current EPS trend and growth estimates. Additionally, we gather related news articles to perform sentiment analysis, providing a holistic view of each company's financial health and market perception.\n",
      "\n",
      "**LLM and RAG Architecture:**\n",
      "\n",
      "To enhance the accuracy and relevance of our stock analysis, we employ the Retrieval-Augmented Generation (RAG) model. Traditional Large Language Models (LLMs) have limitations, such as requiring additional training to adapt to new data and sometimes producing inaccurate information. RAG addresses these issues by incorporating an information retrieval phase into the answer generation process.\n",
      "\n",
      "The RAG model consists of two main phases: retrieval and generation. In the retrieval phase, the model retrieves relevant data from a document database or knowledge base based on the user's question. In the generation phase, the language model generates contextualized answers using the retrieved documents. This approach allows the model to leverage external data in real-time, expanding its knowledge base and improving accuracy.\n",
      "\n",
      "We use LangChain, a framework for developing applications that leverage large-scale language models, to build our RAG system. LangChain provides modular abstractions and customizable pipelines, making it easy to integrate different data sources and interact with other applications. Proper prompt design is essential in this process, as it significantly impacts the quality of the model's output.\n",
      "\n",
      "In conclusion, our research framework combines advanced NLP techniques, dynamic data retrieval systems, and LLMs with RAG architecture to provide comprehensive and reliable stock analysis. By leveraging these cutting-edge technologies, we aim to revolutionize the field of financial stock analysis and enable more informed investment decisions.\n",
      "\n",
      "Thank you for your attention. I look forward to any questions you may have.\n",
      "\n",
      "**Slide Content:**\n",
      "\n",
      "**Slide Title: Research Framework**\n",
      "\n",
      "**Overview of the Methodology:**\n",
      "- Integration of advanced NLP techniques, dynamic data retrieval systems, and LLMs.\n",
      "- Steps: Data collection, data processing, and integration of LLMs with RAG pipelines.\n",
      "- Goal: Enhance accuracy and efficiency in stock market analysis.\n",
      "\n",
      "**Data and Prompting:**\n",
      "- Identification of target companies from Yahoo Finance.\n",
      "- Collection of detailed stock information: EPS trends (90, 60, 30 days), current EPS, growth estimates.\n",
      "- Gathering related news articles for sentiment analysis.\n",
      "\n",
      "**LLM and RAG Architecture:**\n",
      "- Addressing limitations of traditional LLMs with RAG.\n",
      "- RAG model phases: Retrieval and Generation.\n",
      "- Use of LangChain framework for building RAG system.\n",
      "- Importance of proper prompt design for quality output.\n",
      "\n",
      "**Conclusion:**\n",
      "- Combining advanced technologies for comprehensive and reliable stock analysis.\n",
      "- Revolutionizing financial stock analysis for informed investment decisions.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech and relevant slide content for slide \"Research Framework\" that covers the following points:\n",
    "                - Overview of the methodology\n",
    "                - Data and Prompting\n",
    "                - LLM and RAG architecture\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Speech:**\n",
      "\n",
      "Ladies and Gentlemen,\n",
      "\n",
      "Thank you for joining us today. I am excited to delve into the technical components that underpin our advanced financial analysis tools, specifically focusing on GPT-4o and Gemini 1.5 Flash, their system architecture, software design using AWS, and the evaluation process using the BSD detector.\n",
      "\n",
      "**Slide 1: GPT-4o and Gemini 1.5 Flash**\n",
      "\n",
      "Let's start with GPT-4o and Gemini 1.5 Flash, two cutting-edge language models that have revolutionized financial analysis.\n",
      "\n",
      "- **GPT-4o**: Developed by OpenAI, GPT-4o builds on the architecture of its predecessors with enhancements in scale, training data, and fine-tuning techniques. It employs self-attention mechanisms to process and generate text, allowing it to grasp a broad spectrum of language patterns, facts, and reasoning abilities. One of its standout features is its ability to perform zero-shot and few-shot learning, making it highly versatile and capable of handling a wide range of tasks with minimal task-specific training.\n",
      "\n",
      "- **Gemini 1.5 Flash**: Developed by Google, Gemini 1.5 Flash focuses on optimizing efficiency and speed. It employs a hybrid attention mechanism that combines self-attention with cross-attention layers, allowing it to integrate information from multiple sources effectively. Additionally, it utilizes sparse mixture-of-experts (MoE) to selectively activate only a subset of neurons during inference, reducing computational overhead and improving efficiency.\n",
      "\n",
      "**Slide 2: System Architecture and Software Design Using AWS**\n",
      "\n",
      "Next, let's discuss the system architecture and software design using AWS.\n",
      "\n",
      "- **System Architecture**: Our system leverages the robust infrastructure provided by Amazon Web Services (AWS). The architecture is designed to ensure scalability, reliability, and security. Key components include:\n",
      "\n",
      "  - **EC2 Instances**: For scalable compute resources, enabling us to handle large-scale data processing and model inference.\n",
      "  - **S3 Buckets**: For secure and scalable storage of vast amounts of data, including training datasets and model outputs.\n",
      "  - **Lambda Functions**: For serverless computing, allowing us to run code in response to specific events without provisioning or managing servers.\n",
      "  - **RDS**: For managed relational databases, ensuring reliable and scalable database solutions.\n",
      "\n",
      "- **Software Design**: The software design integrates various AWS services to create a seamless workflow for data ingestion, processing, model training, and deployment. Key aspects include:\n",
      "\n",
      "  - **Data Ingestion**: Utilizing AWS Glue and Kinesis for efficient data extraction, transformation, and loading (ETL) processes.\n",
      "  - **Model Training**: Leveraging SageMaker for scalable and managed machine learning training environments.\n",
      "  - **Deployment**: Using Elastic Beanstalk and ECS for deploying and managing applications in a scalable and reliable manner.\n",
      "\n",
      "**Slide 3: Evaluation (BSD Detector)**\n",
      "\n",
      "Finally, let's talk about the evaluation process using the BSD detector.\n",
      "\n",
      "- **BSD Detector**: The BSD (Bias, Safety, and Drift) detector is a critical component in evaluating the performance and reliability of our models. It ensures that the models are not only accurate but also fair, safe, and robust over time.\n",
      "\n",
      "  - **Bias Detection**: The BSD detector identifies and mitigates any biases in the model outputs, ensuring fairness and equity in financial analysis.\n",
      "  - **Safety Checks**: It performs safety checks to prevent harmful or inappropriate outputs, maintaining the integrity and trustworthiness of the system.\n",
      "  - **Drift Monitoring**: The detector continuously monitors for data drift, ensuring that the models remain accurate and relevant as market conditions and data patterns evolve.\n",
      "\n",
      "In conclusion, the combination of GPT-4o and Gemini 1.5 Flash, supported by a robust AWS-based system architecture and rigorous evaluation using the BSD detector, provides a powerful and reliable solution for advanced financial analysis. Thank you for your attention, and I look forward to any questions you may have.\n",
      "\n",
      "**Slide Content:**\n",
      "\n",
      "**Slide 1: GPT-4o and Gemini 1.5 Flash**\n",
      "- **GPT-4o**:\n",
      "  - Developed by OpenAI\n",
      "  - Self-attention mechanisms\n",
      "  - Zero-shot and few-shot learning\n",
      "- **Gemini 1.5 Flash**:\n",
      "  - Developed by Google\n",
      "  - Hybrid attention mechanisms\n",
      "  - Sparse mixture-of-experts (MoE)\n",
      "\n",
      "**Slide 2: System Architecture and Software Design Using AWS**\n",
      "- **System Architecture**:\n",
      "  - EC2 Instances\n",
      "  - S3 Buckets\n",
      "  - Lambda Functions\n",
      "  - RDS\n",
      "- **Software Design**:\n",
      "  - Data Ingestion: AWS Glue, Kinesis\n",
      "  - Model Training: SageMaker\n",
      "  - Deployment: Elastic Beanstalk, ECS\n",
      "\n",
      "**Slide 3: Evaluation (BSD Detector)**\n",
      "- **BSD Detector**:\n",
      "  - Bias Detection\n",
      "  - Safety Checks\n",
      "  - Drift Monitoring\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech and relevant slide content for slide \"Technical Components\" that covers the following points:\n",
    "                - GPT-4o and Gemini 1.5 flash\n",
    "                - System architecture and software design using AWS\n",
    "                - Evaluation (BSD detector)\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Speech:\n",
      "\n",
      "**Title: Request Response Journey: System Architecture and Software Design using AWS**\n",
      "\n",
      "**Introduction:**\n",
      "Good [morning/afternoon/evening] everyone. Today, I am excited to walk you through the request-response journey of our AI Stock Analyst Financial Chatbot. We will delve into the system architecture and the software design using AWS that powers this sophisticated application. This journey ensures that user queries about company stock information and related news sentiments are processed quickly and accurately.\n",
      "\n",
      "**Slide 1: Request Response Journey**\n",
      "\n",
      "**System Architecture:**\n",
      "Our system architecture is designed to be robust, scalable, and efficient. It leverages a combination of AWS services to handle requests, process data, and provide responses to users. The journey begins with DNS resolution via AWS Route 53, which directs end-user requests to the relevant AWS resources. \n",
      "\n",
      "Next, AWS CloudFront, a Content Delivery Network (CDN) service, receives the request. CloudFront ensures low latency and high transfer speeds by caching content at edge locations globally. This reduces the load on the origin servers and ensures prompt processing of requests.\n",
      "\n",
      "The request then passes through the AWS Web Application Firewall (WAF), which protects our web applications from common web exploits and vulnerabilities. AWS WAF ensures that only legitimate requests reach our backend services.\n",
      "\n",
      "Following this, the request is handled by the AWS Network Load Balancer (NLB), which can process millions of requests per second with extremely low latencies. The NLB distributes incoming traffic among multiple targets, such as EC2 instances, across different Availability Zones.\n",
      "\n",
      "**Slide 2: Request Flow through AWS Services**\n",
      "\n",
      "**Software Design using AWS:**\n",
      "The next step in the request flow involves the AWS Application Load Balancer (ALB). The ALB operates at the application layer and offers advanced routing capabilities, ensuring that requests are forwarded to the appropriate backend services based on their content.\n",
      "\n",
      "The AWS API Gateway then takes over, managing traffic, authorization, access control, monitoring, and API version management. It serves as the entry point for our application, facilitating interaction with backend services.\n",
      "\n",
      "AWS Lambda, a serverless compute service, processes the request. Lambda automatically scales to handle varying loads, executing code in response to events. It communicates with backend microservices, including AWS EKS (Elastic Kubernetes Service), AWS ECS (Elastic Container Service), and other Lambda functions.\n",
      "\n",
      "**Slide 3: Backend Microservices and Data Processing**\n",
      "\n",
      "**Backend Microservices:**\n",
      "Our backend microservices include the Scraper Service, Sentiment Analysis Service, LLM Service, and Database Service. The Scraper Service retrieves stock information and related news articles from sources like Yahoo Finance and Yahoo News. The Sentiment Analysis Service analyzes the sentiment of these news articles, generating sentiment scores crucial for understanding market sentiment.\n",
      "\n",
      "The LLM Service feeds the scraped news articles and stock information into a pre-trained Large Language Model (LLM) to generate comprehensive responses to user queries. Finally, the Database Service stores all user queries, responses, and other relevant data in a PostgreSQL database hosted on AWS RDS (Relational Database Service).\n",
      "\n",
      "**Slide 4: Response Generation and Delivery**\n",
      "\n",
      "**Response Generation and Delivery:**\n",
      "The sentiment scores, along with the stock information, are processed by the LLM model to generate a comprehensive response. This response is then sent back to the Lambda function, which formats it and sends it to the user through the API Gateway. Throughout this process, AWS CloudWatch monitors performance and logs any issues, ensuring smooth operation.\n",
      "\n",
      "**Conclusion:**\n",
      "In summary, our system design leverages the scalability, reliability, and efficiency of AWS services to provide accurate and timely responses to user queries. By utilizing services like Route 53, CloudFront, WAF, NLB, ALB, API Gateway, Lambda, ECS, EKS, and RDS, we ensure high availability, security, and performance. This architecture is well-suited for handling the complex task of stock price trend prediction using sentiment analysis of financial headlines.\n",
      "\n",
      "Thank you for your attention. I am happy to take any questions you may have.\n",
      "\n",
      "### Slide Content:\n",
      "\n",
      "**Slide 1: Request Response Journey**\n",
      "- Title: Request Response Journey\n",
      "- Bullet Points:\n",
      "  - DNS resolution via AWS Route 53\n",
      "  - Content delivery with AWS CloudFront\n",
      "  - Security with AWS WAF\n",
      "  - Load balancing with AWS NLB\n",
      "\n",
      "**Slide 2: Request Flow through AWS Services**\n",
      "- Title: Request Flow through AWS Services\n",
      "- Bullet Points:\n",
      "  - Advanced routing with AWS ALB\n",
      "  - API management with AWS API Gateway\n",
      "  - Serverless processing with AWS Lambda\n",
      "\n",
      "**Slide 3: Backend Microservices and Data Processing**\n",
      "- Title: Backend Microservices and Data Processing\n",
      "- Bullet Points:\n",
      "  - Scraper Service: Data retrieval from Yahoo Finance and News\n",
      "  - Sentiment Analysis Service: Sentiment score generation\n",
      "  - LLM Service: Response generation using pre-trained LLM\n",
      "  - Database Service: Data storage with AWS RDS\n",
      "\n",
      "**Slide 4: Response Generation and Delivery**\n",
      "- Title: Response Generation and Delivery\n",
      "- Bullet Points:\n",
      "  - Sentiment scores and stock information processing\n",
      "  - Response formatting and delivery via API Gateway\n",
      "  - Performance monitoring with AWS CloudWatch\n",
      "\n",
      "**Conclusion Slide:**\n",
      "- Title: Conclusion\n",
      "- Bullet Points:\n",
      "  - Scalability, reliability, and efficiency with AWS services\n",
      "  - High availability, security, and performance\n",
      "  - Handling complex stock price trend prediction tasks\n",
      "\n",
      "This structure ensures that the audience understands the comprehensive architecture and the efficient use of AWS services in the request-response journey of our AI Stock Analyst Financial Chatbot.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech and relevant slide content for slide \"Request Response journey\" that covers the following points:\n",
    "                - System Architecture\n",
    "                - Software desgin using AWS\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Speech:**\n",
      "\n",
      "Good [morning/afternoon/evening] everyone,\n",
      "\n",
      "Thank you for joining us today. I am excited to share with you the analysis and findings from our recent study on stock analysis reports generated using Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) techniques. Our research aimed to provide investors with comprehensive, real-time stock analysis reports to aid in their decision-making process. Let's dive into the insights from our results and discuss their implications for investors.\n",
      "\n",
      "**Insights from the Results:**\n",
      "\n",
      "1. **Improved Accessibility of Information:**\n",
      "   Our system significantly enhances the accessibility of stock analysis information. By entering the name of a company, users can receive detailed reports in real-time. This feature allows investors to quickly obtain the information they need, facilitating more accurate and timely investment decisions.\n",
      "\n",
      "2. **Data Integration:**\n",
      "   One of the key strengths of our system is its ability to consolidate data from various sources. By integrating financial data, news summaries, and other relevant information, our reports provide a comprehensive view of the stock market. This holistic approach enables investors to analyze stocks from multiple perspectives, reducing reliance on fragmented information.\n",
      "\n",
      "3. **Real-Time Updates:**\n",
      "   Our system generates reports that reflect the latest data, allowing investors to react swiftly to market volatility. This real-time capability ensures that investors are always making decisions based on the most current information available.\n",
      "\n",
      "**Implications for Investors:**\n",
      "\n",
      "1. **Enhanced Decision-Making:**\n",
      "   The improved accessibility and integration of data mean that investors can make more informed decisions. With comprehensive and up-to-date reports at their fingertips, investors can better assess the potential risks and rewards associated with their investments.\n",
      "\n",
      "2. **Time Efficiency:**\n",
      "   Creating stock analysis reports manually can be time-consuming and labor-intensive. Our system automates this process, saving investors valuable time and effort. This efficiency allows investors to focus on strategic decision-making rather than data collection and analysis.\n",
      "\n",
      "3. **Broader Market Perspective:**\n",
      "   By consolidating data from various sources, our system provides a broader perspective on the stock market. Investors can gain insights into market trends, financial health, and news events that may impact stock performance. This comprehensive view helps investors make more holistic and well-rounded investment decisions.\n",
      "\n",
      "4. **Adaptability to Market Changes:**\n",
      "   The real-time updates provided by our system enable investors to stay ahead of market changes. Whether it's reacting to sudden market volatility or capitalizing on emerging trends, our system ensures that investors have the most relevant information at their disposal.\n",
      "\n",
      "In conclusion, our research has demonstrated the potential of using LLM and RAG techniques to generate reliable and comprehensive stock analysis reports. By improving accessibility, integrating diverse data sources, and providing real-time updates, our system offers significant benefits to investors. We believe that this innovative approach will empower investors to make more informed and strategic investment decisions.\n",
      "\n",
      "Thank you for your attention. I look forward to any questions you may have.\n",
      "\n",
      "**Slide Content:**\n",
      "\n",
      "**Slide Title: Analysis and Findings**\n",
      "\n",
      "**Insights from the Results:**\n",
      "- **Improved Accessibility of Information:**\n",
      "  - Real-time, comprehensive stock analysis reports\n",
      "  - Facilitates accurate and timely investment decisions\n",
      "- **Data Integration:**\n",
      "  - Consolidates data from various sources\n",
      "  - Provides a holistic view of the stock market\n",
      "- **Real-Time Updates:**\n",
      "  - Reflects the latest data\n",
      "  - Enables swift reaction to market volatility\n",
      "\n",
      "**Implications for Investors:**\n",
      "- **Enhanced Decision-Making:**\n",
      "  - Informed decisions with comprehensive, up-to-date reports\n",
      "- **Time Efficiency:**\n",
      "  - Automated report generation saves time and effort\n",
      "- **Broader Market Perspective:**\n",
      "  - Insights into market trends, financial health, and news events\n",
      "- **Adaptability to Market Changes:**\n",
      "  - Stay ahead of market changes with real-time updates\n",
      "\n",
      "Thank you for your attention.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech and relevant slide content for slide \"Analysis and Findings\" that covers the following points:\n",
    "                - Insights from the results\n",
    "                - Implications for investors\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Speech:**\n",
      "\n",
      "\"Good [morning/afternoon/evening] everyone,\n",
      "\n",
      "Today, I am pleased to present the conclusion of our research on financial fraud detection using various machine learning and deep learning models. This study aimed to explore and validate the effectiveness of traditional machine learning methods, deep learning models, and Large Language Models (LLMs) in identifying fraudulent activities within financial reports and statements.\n",
      "\n",
      "**Summary of Key Findings:**\n",
      "\n",
      "Our research has yielded several significant findings. Firstly, we observed that traditional machine learning models such as Logistic Regression and Support Vector Machine (SVM) provided a solid baseline for fraud detection with reasonable accuracy, precision, and recall. However, these models showed limitations in handling complex patterns and large datasets.\n",
      "\n",
      "Deep learning models, including Artificial Neural Networks (ANN) and Hierarchical Attention Networks (HAN), demonstrated improved performance over traditional methods. These models were particularly effective in capturing intricate relationships within the data, leading to higher accuracy and better generalization capabilities.\n",
      "\n",
      "The standout performers in our study were the Large Language Models, specifically FinBERT and GPT-2 with Attention. These models excelled in understanding and interpreting the nuanced language used in financial documents. FinBERT, in particular, showed remarkable precision and recall, making it highly effective in detecting subtle indicators of fraud.\n",
      "\n",
      "**Validation of the Model's Effectiveness:**\n",
      "\n",
      "To validate the effectiveness of these models, we employed rigorous evaluation metrics such as accuracy, precision, F1 score, and recall. The results consistently indicated that LLMs outperformed both traditional and deep learning models in most scenarios. The critical evaluation of these models highlighted their strengths in handling unstructured data and their ability to learn from vast amounts of textual information.\n",
      "\n",
      "In conclusion, our research confirms that while traditional and deep learning models are valuable tools for financial fraud detection, Large Language Models like FinBERT and GPT-2 with Attention offer superior performance and reliability. These findings align with our research objectives and contribute significantly to the field of financial fraud detection.\n",
      "\n",
      "Thank you for your attention. I am happy to take any questions you may have.\"\n",
      "\n",
      "**Slide Content:**\n",
      "\n",
      "**Slide Title: Conclusion**\n",
      "\n",
      "**Summary of Key Findings:**\n",
      "- Traditional ML models (Logistic Regression, SVM) provide a solid baseline.\n",
      "- Deep learning models (ANN, HAN) show improved performance.\n",
      "- LLMs (FinBERT, GPT-2 with Attention) excel in understanding financial language.\n",
      "- FinBERT demonstrates remarkable precision and recall.\n",
      "\n",
      "**Validation of Model's Effectiveness:**\n",
      "- Rigorous evaluation metrics: accuracy, precision, F1 score, recall.\n",
      "- LLMs outperform traditional and deep learning models.\n",
      "- Strengths in handling unstructured data and learning from textual information.\n",
      "\n",
      "**Conclusion:**\n",
      "- LLMs offer superior performance and reliability.\n",
      "- Significant contribution to financial fraud detection field.\n",
      "\n",
      "Thank you!\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            write a 5 minute speech and relevant slide content for slide \"conclusion\" by summarizing the conclusion section in the paper that covers the following points:\n",
    "                - Summary of key findings\n",
    "                - Validation of the model's effectiveness\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here is a summary of the conclusion section in 5 bullet points:\n",
      "\n",
      "1. **Study Focus**: The study primarily examines internal control methods, fraud prevention measures, and financial performance within \"A\" Bank.\n",
      "2. **Objective**: The objective is to assess the internal control practices, their impact on fraud prevention, and the subsequent influence on the bank's financial performance.\n",
      "3. **Data Collection**: Data was collected from 315 workers at the Head Office and branches of \"A\" Bank using simple random sampling.\n",
      "4. **Findings on Control Environment**: The bank has a robust control environment with comprehensive training and clear operational guidelines, contributing to effective fraud mitigation.\n",
      "5. **Risk Management and Control Operations**: \"A\" Bank has a precise and transparent risk management system, conducts regular inventory checks, and implements control operations at multiple levels to prevent fraud.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            summarize the conclusion section in 5 bullet points in page 54,55.\n",
    "        '''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are some possible questions that a computer science professor might ask based on the given documents:\n",
      "\n",
      "### Questions for \"AI Stock Analyst: Financial Chatbot Using Large Language Models\" by Gummadi Sai Dheeraj\n",
      "\n",
      "1. **General Understanding:**\n",
      "   - What is the primary objective of the thesis \"AI Stock Analyst: Financial Chatbot Using Large Language Models\"?\n",
      "   - Who is the advisor for this thesis, and what is the delivery date?\n",
      "\n",
      "2. **Technical Details:**\n",
      "   - What are the main components of the financial chatbot discussed in the thesis?\n",
      "   - How do Large Language Models (LLMs) contribute to the functionality of the financial chatbot?\n",
      "   - What datasets were used to train and evaluate the chatbot?\n",
      "\n",
      "3. **Challenges and Solutions:**\n",
      "   - What are the key challenges faced in developing a financial chatbot using LLMs?\n",
      "   - How does the thesis propose to address the issue of cumulative errors in the SEP framework?\n",
      "\n",
      "4. **Evaluation and Metrics:**\n",
      "   - What metrics are used to evaluate the performance of the financial chatbot?\n",
      "   - Are there any limitations in the current evaluation methods for generated stock explanations?\n",
      "\n",
      "5. **Future Work:**\n",
      "   - What future improvements are suggested for enhancing the robustness of the chatbot?\n",
      "   - How can additional data sources like knowledge graphs or audio features improve the chatbot's predictions?\n",
      "\n",
      "### Questions for \"Detailed Report on Financial Fraud Detection\" by Amit Shushil Kedia\n",
      "\n",
      "1. **General Understanding:**\n",
      "   - What is the main focus of the report \"Enhancing Financial Fraud Detection: A Comparative Analysis of Large Language Models and Traditional Machine Learning and Deep Learning Approaches\"?\n",
      "   - Which university and department is associated with this report?\n",
      "\n",
      "2. **Technical Details:**\n",
      "   - What are the traditional machine learning and deep learning approaches discussed in the report for financial fraud detection?\n",
      "   - How do Large Language Models (LLMs) compare to these traditional approaches in terms of performance?\n",
      "\n",
      "3. **Comparative Analysis:**\n",
      "   - What criteria are used to compare LLMs with traditional machine learning and deep learning approaches?\n",
      "   - What are the key findings of the comparative analysis?\n",
      "\n",
      "4. **Challenges and Solutions:**\n",
      "   - What are the main challenges in financial fraud detection using LLMs?\n",
      "   - How does the report suggest overcoming these challenges?\n",
      "\n",
      "5. **Future Work:**\n",
      "   - What future research directions are proposed for enhancing financial fraud detection?\n",
      "   - How can the integration of LLMs with other technologies improve fraud detection systems?\n",
      "\n",
      "### Questions for the Literature Review (2402.03659v3.pdf)\n",
      "\n",
      "1. **General Understanding:**\n",
      "   - What is the main topic addressed in the literature review document (2402.03659v3.pdf)?\n",
      "\n",
      "2. **Technical Details:**\n",
      "   - What is the SEP framework, and how is it relevant to the topic discussed?\n",
      "   - How can knowledge graphs and audio features enhance the quality of predictions in the context discussed?\n",
      "\n",
      "3. **Challenges and Solutions:**\n",
      "   - What are the potential cumulative errors in the SEP framework, and how can they affect the outcomes?\n",
      "   - What strategies are suggested to increase the robustness of generated responses and reduce the need for human intervention?\n",
      "\n",
      "4. **Evaluation and Metrics:**\n",
      "   - What are the current limitations in evaluating generated stock explanations?\n",
      "   - What improvements are suggested for the metrics used in this work?\n",
      "\n",
      "5. **Future Work:**\n",
      "   - What areas are identified for further studies to improve the evaluation of generated stock explanations?\n",
      "   - How can exploring the multi-modal capabilities of recent LLM upgrades contribute to the field?\n",
      "\n",
      "These questions cover a broad range of topics, including general understanding, technical details, challenges, solutions, evaluation, and future work, providing a comprehensive examination of the documents.\n"
     ]
    }
   ],
   "source": [
    "prompt = ''' \n",
    "            Imagine you are computer science professor. \n",
    "            ask all the possible quesitons for the given docuemtns.\n",
    "\n",
    "'''\n",
    "print(query_engine.query(prompt).response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unstructured_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
